{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6104e749-9177-4d40-b3de-860256284e01",
   "metadata": {},
   "source": [
    "# DQN on Images with Keras-RL2 - Pong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74565c8-99ba-4fcd-94f6-81452299ccec",
   "metadata": {},
   "source": [
    "This notebook implements **DQN on Images** for the [Pong](https://gym.openai.com/envs/Pong-v0/) game. The Keras-RL2 abstraction library is used. This notebook builds up on the previous one without adding special novelties.\n",
    "\n",
    "For general theory and intuition, see`../ReinforcementLearning_Guide.md`.\n",
    "\n",
    "Overview:\n",
    "1. Imports\n",
    "2. Environment Setup\n",
    "3. Image Processing\n",
    "4. Network Model\n",
    "5. Agent\n",
    "6. Training & Storing\n",
    "7. Test & Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963547c3-fb4d-4215-a683-bd6967b5826b",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ee953f-5624-4d20-9641-251fda25ab4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\.conda\\envs\\ds\\lib\\site-packages\\ale_py\\roms\\utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n"
     ]
    }
   ],
   "source": [
    "# Image processing\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "#from gym.utils import play\n",
    "\n",
    "# CNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Keras-RL2\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint # for tracking results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead89b8f-732a-4c8e-8713-9a087302cbe0",
   "metadata": {},
   "source": [
    "## 2. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b11b082-0e9d-4626-95ce-d69df29c44bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"Pong-v0\"\n",
    "env = gym.make(env_name)\n",
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a3cb557-af18-431f-ac8d-d9c71025e520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab6fad0-9c66-43b8-a6eb-3046b95ec9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd22074-17dc-4374-bce3-3793649ac5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#play.play(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0846d4dd-3227-449f-8077-604a9e10b648",
   "metadata": {},
   "source": [
    "## 3. Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7282d9a1-b7a3-4145-a168-d8d20114e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b306fa9-c205-4c06-8fd7-7b0f63e4d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        img = Image.fromarray(observation)\n",
    "        img = img.resize(IMG_SHAPE)\n",
    "        img = img.convert(\"L\")\n",
    "        img = np.array(img)\n",
    "        return img.astype('uint8')\n",
    "    def process_state_batch(self, batch):\n",
    "        processed_batch = batch.astype('float32') / 255.\n",
    "        return processed_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc27bfa-b981-4b20-957c-b8f04569fd80",
   "metadata": {},
   "source": [
    "## 4. Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34555677-07f9-42ed-9b87-b4d7be2ca969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute (Permute)            (None, 84, 84, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 20, 20, 32)        8224      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 64)          32832     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 3078      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,687,206\n",
      "Trainable params: 1,687,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (WINDOW_LENGTH, IMG_SHAPE[0], IMG_SHAPE[1])\n",
    "# Model definition\n",
    "model = Sequential()\n",
    "model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "model.add(Convolution2D(32, (8, 8), strides=(4, 4),kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (4, 4), strides=(2, 2), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "# Print model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba267cea-31dc-404c-ab79-1d1fb0b0662a",
   "metadata": {},
   "source": [
    "## 5. Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ed6ccb5-6f2a-44a2-a1e7-bec8a9f2177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay buffer\n",
    "memory = SequentialMemory(limit=100000, window_length=WINDOW_LENGTH) # It should be x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca255fd-819f-4d5c-99b8-36a3ad9a707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa6d44dd-127a-4344-aafc-f36688de25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(),\n",
    "                              attr='eps',\n",
    "                              value_max=1.,\n",
    "                              value_min=.1,\n",
    "                              value_test=.05,\n",
    "                              nb_steps=100000) # It should be x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1871940-30bd-43ef-b673-e62544c80d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQNAgent(model=model,\n",
    "               nb_actions=nb_actions,\n",
    "               policy=policy,\n",
    "               memory=memory,\n",
    "               processor=processor,\n",
    "               nb_steps_warmup=50000,\n",
    "               gamma=0.99,\n",
    "               target_model_update=10000,\n",
    "               train_interval=4,\n",
    "               delta_clip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7846dd98-95a0-44d5-bb5e-04b704ac7090",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.compile(Adam(learning_rate=.00025), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5ccb04-5c06-4d9e-b2cd-e8cb584f8f23",
   "metadata": {},
   "source": [
    "## 6. Training & Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f03b52ad-0277-444d-b566-ce9594ad2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store it as HDF5: 2 files are stored (h5f.data* and h5f.index), but we refer to the .h5f ending only\n",
    "weights_filename = 'dqn_' + env_name + '_weights.h5f'\n",
    "checkpoint_weights_filename = 'dqn_' + env_name + '_weights_{step}.h5f'\n",
    "# Every interval steps, model weights saved\n",
    "checkpoint_callback = ModelIntervalCheckpoint(checkpoint_weights_filename, interval=10000) # Should bd x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4a91806-ed08-4124-bd29-7db2e13b2390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "   30/10000 [..............................] - ETA: 35s - reward: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\.conda\\envs\\ds\\lib\\site-packages\\keras\\engine\\training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 33s 3ms/step - reward: -0.0169\n",
      "done, took 33.094 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244dca4fe88>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "# log_interval: output frequency\n",
    "# nb_steps: steps to train; watch out: if it is pretrained, then we need less\n",
    "# but we definitely need more than 10000 steps...\n",
    "dqn.fit(env, nb_steps=10000, callbacks=[checkpoint_callback], log_interval=10000, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9806430f-c017-439a-914a-e338c3f27858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "dqn.save_weights(weights_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a214130e-7f05-453d-93c8-6ce792348905",
   "metadata": {},
   "source": [
    "## 7. Test & Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d47fa19-fb95-4664-983f-a918206109f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\.conda\\envs\\ds\\lib\\site-packages\\gym\\envs\\atari\\environment.py:257: UserWarning: \u001b[33mWARN: We strongly suggest supplying `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). Using `render_mode` provides access to proper scaling, audio support, and proper framerates.\u001b[0m\n",
      "  \"We strongly suggest supplying `render_mode` when \"\n",
      "C:\\Users\\Mikel\\.conda\\envs\\ds\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: reward: -21.000, steps: 1016\n",
      "Episode 2: reward: -21.000, steps: 1019\n",
      "Episode 3: reward: -21.000, steps: 1026\n",
      "Episode 4: reward: -21.000, steps: 1014\n",
      "Episode 5: reward: -21.000, steps: 1010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244d65e36c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is a very bad agent, because did not train long enough\n",
    "dqn.test(env, nb_episodes=5, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafe5cac-4c80-458a-895b-7d7624400296",
   "metadata": {},
   "source": [
    "### Model Provided in the Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd8f7bc0-9b45-43b9-bf99-124c575a52fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"C:/Users/Mikel/Dropbox/Learning/PythonLab/udemy_rl_ai/notebooks/08-Deep-Q-Learning-On-Images/weights_exercise/dqn_PONG_weights_1500000.h5f\"\n",
    "model.load_weights(weights_path)\n",
    "# Redefinition of memory & policy\n",
    "memory = SequentialMemory(limit=1000000,\n",
    "                          window_length=WINDOW_LENGTH)\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(),\n",
    "                              attr='eps',\n",
    "                              value_max=1,\n",
    "                              value_min=.1,\n",
    "                              value_test=.05,\n",
    "                              nb_steps=100000)\n",
    "processor = ImageProcessor()\n",
    "dqn = DQNAgent(model=model,\n",
    "               nb_actions=nb_actions,\n",
    "               policy=policy,\n",
    "               memory=memory,\n",
    "               processor=processor,\n",
    "               nb_steps_warmup=50000,\n",
    "               gamma=0.99,\n",
    "               target_model_update=10000)\n",
    "dqn.compile(Adam(lr=.00025), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19c0b310-6aca-4f52-b081-7a9f9c32496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: -13.000, steps: 4615\n",
      "Episode 2: reward: -7.000, steps: 4858\n",
      "Episode 3: reward: -11.000, steps: 4344\n",
      "Episode 4: reward: -17.000, steps: 4053\n",
      "Episode 5: reward: -13.000, steps: 4694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244ded54888>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, this is much better\n",
    "dqn.test(env, nb_episodes=5, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76347bbf-49d3-4c90-b4d2-5d4b017c7346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
