{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79443f8f-757c-4322-b721-facb771e8449",
   "metadata": {},
   "source": [
    "# Q-Learning: Continuous Example with CartPole"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16370d-f21e-45c5-907f-2fb810c5ee17",
   "metadata": {},
   "source": [
    "This notebook implements the Q-Learning algorithm for the [CartPole](https://gym.openai.com/envs/CartPole-v1/) game.\n",
    "See `../ReinforcementLearning_Guide.md` for theory and intuition.\n",
    "\n",
    "According to the OpenAI environment page of CartPole: \"A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force to the left (0) or right (1) of the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright (i.e., does not fall). The episode ends when the pole is more than 12 degrees from vertical, or the cart moves more than 2.4 units from the center.\"\n",
    "\n",
    "Note that I needed to change the description above, since it is outdated on the web page.\n",
    "\n",
    "Look at the Github page of the environment, on the docstring of the environment.\n",
    "\n",
    "Note the following:\n",
    "- The center position is 0 and the range of possibles postions is `[-2.4,2.4]`, continuous\n",
    "- Pole angle can vary in `[-12,12] deg`\n",
    "- Velocity (linear for cart, angular for pole) can be any\n",
    "- An episode is done if\n",
    "    1. The pole tresspasses the limits above\n",
    "    2. 200 steps/actions taken\n",
    "    3. A minimum return is achieved over 100 steps/actions\n",
    "\n",
    "We need to discretize the domains using bins.\n",
    "The unique difference in the Q-Learning process compared to a discrete environemnt (as in FrozenLake) is the mapping from the continuous domain to the discrete.\n",
    "\n",
    "Overview of sections:\n",
    "\n",
    "1. Basic Setup of CartPole\n",
    "2. Q Table Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6645d5ea-e8c1-474e-b393-5c7dfa1dcf73",
   "metadata": {},
   "source": [
    "## 1. Basic Setup of CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "057568f0-ca29-4d8f-ac63-35031009d94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mxagar/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gym\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcafb594-4e41-481e-a318-da0a69f28aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 12:32:16.227 python[91016:2954731] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fd35f89ae20>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2022-01-13 12:32:16.227 python[91016:2954731] Warning: Expected min height of view: (<NSButton: 0x7fd3a81494b0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2022-01-13 12:32:16.228 python[91016:2954731] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fd3a8149c40>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2022-01-13 12:32:16.229 python[91016:2954731] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fd3a8142b90>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: [ 0.01955238 -0.22954053  0.02286752  0.26312542]\n",
      "Observation: [ 0.01496157 -0.03475232  0.02813003 -0.02225803]\n",
      "Observation: [ 0.01426652  0.15995516  0.02768487 -0.30593458]\n",
      "Observation: [ 0.01746563  0.3546719   0.02156617 -0.5897594 ]\n",
      "Observation: [ 0.02455907  0.1592547   0.00977099 -0.29036185]\n",
      "Observation: [ 0.02774416 -0.0360052   0.00396375  0.00538665]\n",
      "Observation: [ 0.02702405  0.15905967  0.00407148 -0.28604305]\n",
      "Observation: [ 0.03020525  0.35412332 -0.00164938 -0.57743907]\n",
      "Observation: [ 0.03728772  0.15902454 -0.01319816 -0.2852762 ]\n",
      "Observation: [ 0.0404682  -0.03590672 -0.01890368  0.00321507]\n",
      "Observation: [ 0.03975007 -0.23075254 -0.01883938  0.28987423]\n",
      "Observation: [ 0.03513502 -0.03536708 -0.0130419  -0.0086904 ]\n",
      "Observation: [ 0.03442768  0.15993945 -0.01321571 -0.3054595 ]\n",
      "Observation: [ 0.03762647 -0.0349917  -0.0193249  -0.01697361]\n",
      "Observation: [ 0.03692663 -0.22983125 -0.01966437  0.26955   ]\n",
      "Observation: [ 0.03233001 -0.42466715 -0.01427337  0.5559664 ]\n",
      "Observation: [ 0.02383667 -0.6195858  -0.00315404  0.84411836]\n",
      "Observation: [ 0.01144495 -0.42442098  0.01372833  0.55044526]\n",
      "Observation: [ 0.00295653 -0.22949451  0.02473723  0.2621191 ]\n",
      "Observation: [-0.00163336 -0.03473424  0.02997961 -0.02265989]\n",
      "Observation: [-0.00232804 -0.23027301  0.02952642  0.27932915]\n",
      "Observation: [-0.0069335  -0.03558444  0.035113   -0.00389691]\n",
      "Observation: [-0.00764519 -0.2311919   0.03503506  0.29965454]\n",
      "Observation: [-0.01226903 -0.0365864   0.04102815  0.01822361]\n",
      "Observation: [-0.01300076  0.15792388  0.04139262 -0.26123738]\n",
      "Observation: [-0.00984228 -0.03776376  0.03616788  0.0442086 ]\n",
      "Observation: [-0.01059756  0.1568214   0.03705205 -0.2368472 ]\n",
      "Observation: [-0.00746113 -0.03880978  0.03231511  0.06728896]\n",
      "Observation: [-0.00823732  0.15583433  0.03366088 -0.21502578]\n",
      "Observation: [-0.00512064  0.35045928  0.02936037 -0.49690342]\n",
      "Observation: [ 0.00188855  0.5451552   0.0194223  -0.7801907 ]\n",
      "Observation: [ 0.01279165  0.3497717   0.00381849 -0.48146093]\n",
      "Observation: [ 0.01978709  0.54483956 -0.00581073 -0.77293795]\n",
      "Observation: [ 0.03068388  0.34979802 -0.02126949 -0.48208895]\n",
      "Observation: [ 0.03767984  0.15498264 -0.03091127 -0.19618472]\n",
      "Observation: [ 0.04077949  0.3505328  -0.03483497 -0.4984563 ]\n",
      "Observation: [ 0.04779015  0.54612815 -0.04480409 -0.8019107 ]\n",
      "Observation: [ 0.05871271  0.35164833 -0.06084231 -0.5236517 ]\n",
      "Observation: [ 0.06574567  0.5475714  -0.07131534 -0.8348692 ]\n",
      "Observation: [ 0.0766971   0.3534924  -0.08801273 -0.56543964]\n",
      "Observation: [ 0.08376695  0.54973173 -0.09932151 -0.8845016 ]\n",
      "Observation: [ 0.09476159  0.74605185 -0.11701155 -1.206683  ]\n",
      "Observation: [ 0.10968262  0.55261976 -0.14114521 -0.9528419 ]\n",
      "Observation: [ 0.12073502  0.74932975 -0.16020204 -1.2863317 ]\n",
      "Observation: [ 0.13572161  0.5565676  -0.18592867 -1.0477891 ]\n",
      "Observation: [ 0.14685297  0.7536043  -0.20688446 -1.3925989 ]\n",
      "Observation: [ 0.16192505  0.9506125  -0.23473644 -1.7422006 ]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "env.reset()\n",
    "\n",
    "for step in range(100):\n",
    "    env.render()\n",
    "    action = env.action_space.sample() # 0 or 1\n",
    "    # 4 observations done each step:\n",
    "    # cart position, cart velocity, pole angle, pole angular velocity\n",
    "    observation,reward,done,info = env.step(action)\n",
    "    print(f'Observation: {observation}')\n",
    "    time.sleep(0.02)\n",
    "    if done:\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8034b23-db5c-4052-a057-5bbb02c18f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 12:29:17.697 python[91016:2954731] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fd3a8091420>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2022-01-13 12:29:17.697 python[91016:2954731] Warning: Expected min height of view: (<NSButton: 0x7fd3a809b220>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2022-01-13 12:29:17.699 python[91016:2954731] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fd3a809b9b0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2022-01-13 12:29:17.700 python[91016:2954731] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fd3a809c730>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You got 8 points!\n"
     ]
    }
   ],
   "source": [
    "# We can also play it manually\n",
    "action = 0\n",
    "k = 0\n",
    "def key_press(k, mod):\n",
    "    '''\n",
    "    This function gets the key press for gym\n",
    "    '''\n",
    "    global action\n",
    "    if k == key.LEFT:\n",
    "        action = 0\n",
    "    if k == key.RIGHT:\n",
    "        action = 1\n",
    "\n",
    "env.reset()\n",
    "rewards = 0\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    env.viewer.window.on_key_press = key_press  # update the key press\n",
    "    observation, reward, done, info = env.step(action)  # get the reward and the done flag\n",
    "    rewards+=1\n",
    "    if done:\n",
    "        print(f\"You got {rewards} points!\")\n",
    "        break\n",
    "    time.sleep(0.5)  # reduce speed a little bit (edit as needed on you computer)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a73ff-fe37-4204-bc5f-86bcadbdfde5",
   "metadata": {},
   "source": [
    "## 2. Q Table Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf1ef9-f70c-4968-9d03-f839166b4043",
   "metadata": {},
   "source": [
    "In the FrozenLake environment we had one observation which mapped to a unique state variable. Now, we have 4 observation variables and they map to one state. And recall that the Q-Learning table is `state x action`.\n",
    "\n",
    "To address that issue, we discretize each observation variable in bins and build from the combinations of those observation-bins all possible discrete states. We can represent that in two forms:\n",
    "- We build a multidimensional matrix/array: dimensions are `observations + action`. Each observation dimension is discretized/binned in all defined ranges and the action dimension contains all possible actions; then, each combination of `observations + actions` has a Q value. Thus, 4 observation values lead to a dimension of 5 (`observations + action`). Each dimension has the size of the number of bins or the number of actions. Example: `4` observations, each one with `3` bins and additionally `2` actions: `np.zeros((3,3,3,3,2))`. Then, each cell maps to a possible Q value.\n",
    "- Note that combining `observations` and `bins` we get all the `states`. Thus, we can further develop the structure above to have `3^4` states and `2` actions. However, the multidimensional array is more comfortable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15c27d3f-7544-45b0-90e4-8badb1e3cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ceffc5b-bac9-4e2e-91c2-ec83f9b663ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((3,3,3,3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16cc7e8-9839-40bc-96d4-508176473484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
