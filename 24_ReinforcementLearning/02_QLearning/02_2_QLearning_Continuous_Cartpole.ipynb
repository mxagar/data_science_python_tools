{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79443f8f-757c-4322-b721-facb771e8449",
   "metadata": {},
   "source": [
    "# Q-Learning: Continuous Example with CartPole"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16370d-f21e-45c5-907f-2fb810c5ee17",
   "metadata": {},
   "source": [
    "This notebook implements the Q-Learning algorithm for the [CartPole](https://gym.openai.com/envs/CartPole-v1/) game.\n",
    "See `../ReinforcementLearning_Guide.md` for theory and intuition.\n",
    "\n",
    "According to the OpenAI environment page of CartPole: \"A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center.\"\n",
    "\n",
    "Overview of sections:\n",
    "\n",
    "1. Basic Setup of CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f269e-ad81-47d7-8ca4-d735e9fc2984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
