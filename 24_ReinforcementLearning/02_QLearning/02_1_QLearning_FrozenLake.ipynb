{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f501400-522f-4ce0-a88e-56f7b47d332d",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76024045-2569-42b2-9752-07fd213f2814",
   "metadata": {},
   "source": [
    "This notebook implements the Q-Learning algorithm for the [FrozenLake](https://gym.openai.com/envs/FrozenLake-v0/) game.\n",
    "See `../ReinforcementLearning_Guide.md` for theory and intuition.\n",
    "\n",
    "According to the OpenAI environment page of FrozenLake: \"The agent controls the movement of a character in a grid world. Some tiles of the grid are walkable, and others lead to the agent falling into the water. Additionally, the movement direction of the agent is uncertain and only partially depends on the chosen direction. The agent is rewarded for finding a walkable path to a goal tile.\"\n",
    "\n",
    "The surface is described using a grid:\n",
    "\n",
    "    SFFF       (S: starting point, safe)\n",
    "    FHFH       (F: frozen surface, safe)\n",
    "    FFFH       (H: hole, fall to your doom)\n",
    "    HFFG       (G: goal, where the frisbee is located)\n",
    "\n",
    "The game episode ends when the agent reaches the goal or it falls in a hole. You receive a reward of 1 if you reach the goal, zero otherwise.\n",
    "\n",
    "We are going to disable the slippery property; otherwise taken actions are not carried out necessarily, and the learning process takes longer. That change is after this post:\n",
    "\n",
    "[https://github.com/openai/gym/issues/565](https://github.com/openai/gym/issues/565)\n",
    "\n",
    "Overview of sections:\n",
    "\n",
    "1. Basic setup of FrozenLake\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b595d-b5ac-4381-a800-d9f0f9d2fc26",
   "metadata": {},
   "source": [
    "## 1. Basic setup of FrozenLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accfeafb-7f04-4b74-a8b4-88cd27e99348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "973fc565-0d01-487e-a744-008db5a715b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mxagar/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n"
     ]
    }
   ],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce06230b-c128-4c5d-b326-dfdae6bb6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to remove the slippery tiles, we need to create/register a new environment\n",
    "# with custom properties.\n",
    "# That can be done as explained on this link\n",
    "# https://github.com/openai/gym/issues/565\n",
    "from gym.envs.registration import register\n",
    "try:\n",
    "    register(\n",
    "        id='FrozenLakeNotSlippery-v0', # our custom name\n",
    "        entry_point='gym.envs.toy_text:FrozenLakeEnv', # take the FrozenLakeEnv as the template\n",
    "        kwargs={'map_name' : '4x4', 'is_slippery': False}, # changes we apply; look at Github\n",
    "        max_episode_steps=100, # default 100; 100 steps allowed in an episode\n",
    "        # the reward_threshold makes sense for games with continuous rewards\n",
    "        # such as the cart pole; but not really here\n",
    "        # we leave the default, though\n",
    "        reward_threshold=.8196, # optimum = .8196\n",
    "    )\n",
    "except:\n",
    "    print('A new env can be registered only once.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5329a42a-4623-4f1c-859e-fe898b4dc563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "# We create an env and play in it\n",
    "# Note that the environment is completely rendered after each step/action\n",
    "env = gym.make('FrozenLakeNotSlippery-v0')\n",
    "env.reset()\n",
    "\n",
    "for step in range(5):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    env.step(action)\n",
    "    #time.sleep(0.5)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fcb9fd5-0051-42a1-8349-1129168374e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clear/flush the text display we can use clear_output on Jupyter\n",
    "from IPython.display import clear_output\n",
    "# On python scripts:\n",
    "# import os\n",
    "# os.system('clear') # 'cls' ono Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "254e9467-9780-4810-8438-7c891f658b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "# We create an env and play in it\n",
    "env = gym.make('FrozenLakeNotSlippery-v0')\n",
    "env.reset()\n",
    "\n",
    "for step in range(10):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation,reward,done,info = env.step(action)\n",
    "    time.sleep(0.2)\n",
    "    clear_output(wait=True)\n",
    "    if done:\n",
    "        env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3640818-4e2d-4ba6-a6fe-5dd3e400987b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
