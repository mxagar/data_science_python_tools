{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa63394d-08a5-4802-baf8-6b41ac34bc37",
   "metadata": {},
   "source": [
    "# Manual DQN - Cartpole"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c5fca9-07e9-48a0-ba2b-55cee044ca3a",
   "metadata": {},
   "source": [
    "This notebook implements the **Deep Q Network (DQN)** for the [CartPole](https://gym.openai.com/envs/CartPole-v1/) game manually.\n",
    "See `../ReinforcementLearning_Guide.md` for theory and intuition.\n",
    "\n",
    "According to the OpenAI environment page of CartPole: \"A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force to the left (0) or right (1) of the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright (i.e., does not fall). The episode ends when the pole is more than 12 degrees from vertical, or the cart moves more than 2.4 units from the center.\"\n",
    "\n",
    "Note that I needed to change the description above, since it is outdated on the web page.\n",
    "\n",
    "Look at the Github page of the environment, on the docstring of the environment.\n",
    "\n",
    "Note the following:\n",
    "- The center position is 0 and the range of possibles postions is `[-2.4,2.4]`, continuous\n",
    "- Pole angle can vary in `[-12,12] deg`\n",
    "- Velocity (linear for cart, angular for pole) can be any\n",
    "- An episode is done if\n",
    "    1. The pole tresspasses the limits above\n",
    "    2. 200 steps/actions taken\n",
    "    3. A minimum return is achieved over 100 steps/actions\n",
    "\n",
    "We need to discretize the domains using bins.\n",
    "\n",
    "Overview of sections:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72aff0ce-a177-4b53-b3e5-5600af3c2d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mxagar/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb192086-234d-42b0-8aa0-8c1d1327f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential,clone_model\n",
    "from tensorflow.keras.layers import Dense,Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a6998-f5e2-455f-b9ed-b42a8087770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
